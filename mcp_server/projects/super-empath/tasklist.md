# Super Empath LLM Integration - Task List

## Project Overview
This project enhances the Super Empath Telegram bot to use LLM-based responses instead of hardcoded logic. The system will maintain conversation history for each user and provide contextual, empathetic responses using a structured prompt template.

## Task Breakdown

### Task 1: Create Project Documentation ‚úÖ
**Description:** Create tasklist.md and update readme.md in projects/super-empath/ with task decomposition and project overview

**Implementation Details:**
- Document the complete project scope and requirements
- Create this task list with clear acceptance criteria
- Update readme.md with technical specifications

**Testing:** Review documentation completeness and clarity

**Acceptance Criteria:**
- [x] tasklist.md created with all tasks
- [x] readme.md updated with project overview
- [x] Technical requirements documented

---

### Task 2: Create Prompt Template File ‚úÖ
**Description:** Create prompt template file in projects/super-empath/prompt/default_super_empath.txt with the specified prompt structure

**Implementation Details:**
- Create directory structure: `projects/super-empath/prompt/`
- Create `default_super_empath.txt` with the empathy prompt from requirements
- Exact prompt text: "–¢—ã —Å—É–ø–µ—Ä —ç–º–ø–∞—Ç, —Ç–≤–æ—è –∑–∞–¥–∞—á–∞ –ø–æ–º–æ—á—å —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞–º –¥–æ–≥–æ–≤–æ—Ä–∏—Ç—å—Å—è..."
- Template should include placeholders for: `{conversation_history}`, `{user_message}`, `{user_id}`
- Prompt should request structured JSON output with `explanation` and `suggestion` fields
- Avoid "—ë" characters (use "–µ") and long dashes (use "-") as specified
- Response should not sound "plastic" or artificial

**Testing:** Validate template syntax and placeholder structure

**Acceptance Criteria:**
- [x] Prompt directory created
- [x] Template file contains complete empathy prompt
- [x] JSON structure specified correctly
- [x] Character restrictions applied (no "—ë", no long dashes)

---

### Task 3: Update Telegram Pipeline Config ‚úÖ
**Description:** Transform telegram_pipeline.json into a batch pipeline that loads prompt and saves it as template, then calls telegram tool

**Implementation Details:**
- Convert current telegram_pipeline.json to batch pipeline format
- Add step to load prompt from file using `lng_file_read`
- Add step to save prompt template using `lng_llm_prompt_template save`
- Keep existing telegram tool call with current parameters
- Configure template name as "default_super_empath"
- Use pipeline_file approach instead of inline pipeline for better expression handling

**Testing:** Validate pipeline syntax and execution order

**Acceptance Criteria:**
- [x] Pipeline loads prompt from file
- [x] Pipeline saves template with correct name
- [x] Pipeline calls telegram tool with pipeline_file reference
- [x] All steps have proper output variables
- [x] Expression evaluation works correctly with telegram context

---

### Task 4: Implement Session History Management ‚úÖ
**Description:** Add session/user history management to super-empath tool with file storage in config/telegram/sessions/<sessionId>/<userId>.txt

**Implementation Details:**
- Create session directory structure automatically
- Implement history file format: `[USER_ID|USER_NAME]: message content`
- Support multi-line messages (preserve line breaks)
- Include EMPATH responses in history as `[EMPATH]: response content`
- Handle special commands like `—Ç–∞–º–∞–º`, `–æ—Ç–±–æ–π` (not `/tamam`, `/cancel`)
- Each user sees: own messages + messages from others + empath responses
- Load existing history when processing new messages
- Append new messages to history files
- Create separate history file per user per session

**Testing:** Test history creation, loading, and appending with mock data

**Acceptance Criteria:**
- [x] Session directories created automatically
- [x] History files follow specified format
- [x] Multi-line messages handled correctly
- [x] History loading works for existing users
- [x] New messages appended correctly

---

### Task 5: Modify Super-Empath Tool for LLM Integration ‚úÖ
**Description:** Replace hardcoded logic with LLM calls using lng_llm_prompt_template through tool_registry.py, implement structured JSON output parsing

**Implementation Details:**
- Import and use tool_registry.py for LLM calls
- Replace hardcoded response logic with `lng_llm_prompt_template use`
- Pass conversation history, user message, and user ID as parameters
- Parse structured JSON response with `explanation` and `suggestion`
- Handle LLM response errors gracefully
- Maintain backward compatibility for error cases

**Testing:** Test LLM integration with various message types and history scenarios

**Acceptance Criteria:**
- [x] Hardcoded logic removed
- [x] LLM calls implemented via tool_registry
- [x] JSON response parsing works correctly
- [x] Error handling implemented
- [x] All parameters passed correctly to LLM

---

### Task 6: Implement Named Bot Management ‚úÖ
**Description:** Add named bot instances to avoid conflicts when multiple bots are running

**Implementation Details:**
- Replace global `_server_instance` with `_server_instances` dictionary
- Add `bot_name` parameter to telegram polling server operations
- Implement automatic cleanup of old instances when starting new bot with same name
- Update pipeline configuration to use named bots
- Add proper status reporting for named instances

**Testing:** Test multiple named bot instances and proper cleanup

**Acceptance Criteria:**
- [x] Named bot instances implemented
- [x] Automatic cleanup of conflicting instances
- [x] Pipeline configuration updated with bot_name

---

### Task 7: Implement Emoji Logging System ‚úÖ
**Description:** Add comprehensive emoji-based logging system for better session history tracking and LLM context

**Implementation Details:**
- Create universal `_save_to_history` method for all message types
- Implement emoji markers for different message types (‚öôÔ∏èü§îü§ñüí°ü§ñ‚¨ÖÔ∏èü§ñüí¨‚úÖ‚ùå‚û°Ô∏è)
- Add proper method wrappers for specific message types
- Update session history format to include emoji prefixes
- Ensure LLM receives properly formatted history with emoji context

**Testing:** Test emoji logging across all message types and user interactions

**Acceptance Criteria:**
- [x] Universal logging method implemented
- [x] Emoji system documented and working
- [x] All message types properly categorized
- [x] LLM receives emoji-formatted history

---

### Task 8: Optimize Command Handling ‚úÖ
**Description:** Replace hardcoded commands with proper /command format and improve user experience

**Implementation Details:**
- Change commands from "—Ç–∞–º–∞–º"/"–æ—Ç–±–æ–π" to "/tamam"/"/cancel"
- Implement proper command parsing in handle_command method
- Add simplified response formatting for better user experience
- Update auto_send mechanism for approved messages
- Improve error handling and user feedback

**Testing:** Test all command variations and user flows

**Acceptance Criteria:**
- [x] Proper /command format implemented
- [x] Simplified response formatting
- [x] Auto-send mechanism working
- [x] Improved user experience

---

### Task 9: Documentation Update ‚úÖ
**Description:** Update all project documentation to reflect current implementation state

**Implementation Details:**
- Update examples.md with correct command format and emoji system
- Rewrite readme.md to reflect actual architecture and features
- Update super-empath-bot.agent.md with current pipeline structure
- Update tasklist.md to show completed status
- Ensure all documentation matches current code implementation

**Testing:** Review documentation completeness and accuracy

**Acceptance Criteria:**
- [x] examples.md updated with current commands and emoji system
- [x] readme.md rewritten to match actual implementation
- [x] super-empath-bot.agent.md updated with current structure
- [x] tasklist.md reflects completed project status

---

## Project Status: COMPLETED ‚úÖ

All core features have been successfully implemented and tested:

1. ‚úÖ **LLM Integration** - Fully working with lng_llm_prompt_template
2. ‚úÖ **Session Management** - UUID-based sessions with proper file structure
3. ‚úÖ **Emoji Logging System** - Comprehensive emoji-based message categorization
4. ‚úÖ **Named Bot Management** - Conflict-free bot instances
5. ‚úÖ **Command System** - Proper /command format with user-friendly responses
6. ‚úÖ **Pipeline Architecture** - File-based configuration with expression support
7. ‚úÖ **Auto-Send Mechanism** - Seamless message delivery to session participants
8. ‚úÖ **Documentation** - Complete and up-to-date documentation suite

## Next Steps (Future Enhancements)

### Phase 2: Enhanced Features
- [ ] RAG –±–∞–∑–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è LLM –æ—Ç–≤–µ—Ç–æ–≤
- [ ] –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä—ã/–≥—Ä—É–ø–ø—ã
- [ ] –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–µ–Ω–∏—è
- [ ] Web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏—è–º–∏

### Phase 3: Advanced Features  
- [ ] –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
- [ ] –ü—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞—Ö
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–∞–ª–µ–Ω–¥–∞—Ä–µ–º –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
- [ ] –ö–æ—É—á–∏–Ω–≥-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π
- [x] Status reporting works for named bots
- [x] No "Conflict: terminated by other getUpdates request" errors

---

### Task 7: Test and Validate Implementation ‚úÖ
**Description:** Test the complete pipeline with mock telegram data and validate JSON response parsing

**Implementation Details:**
- Create test scenarios with mock telegram messages
- Test session creation and history management
- Validate LLM responses and JSON parsing
- Test error handling scenarios
- Verify pipeline execution from start to finish
- Test with multiple users and sessions

**Testing:** Comprehensive testing of all components

**Acceptance Criteria:**
- [x] Pipeline executes successfully end-to-end
- [x] History management works correctly
- [x] LLM responses are properly structured
- [x] Error scenarios handled gracefully
- [x] Multiple user scenarios tested

## Important Requirements from Discussion
- **Commands in Russian:** Use `—Ç–∞–º–∞–º` (not `/tamam`) and `–æ—Ç–±–æ–π` (not `/cancel`)
- **Character restrictions:** Replace "—ë" with "–µ", use "-" instead of long dashes
- **Response tone:** Avoid "plastic" or artificial sounding responses
- **Context is critical:** LLM must see full conversation history for each user
- **User perspective:** Each user sees their own messages + what others sent + empath responses
- **File-based config:** Single pipeline file with embedded configurations, no external references
- **Tool integration:** Use existing `lng_llm_prompt_template` through `tool_registry.py`

## Notes
- Each task should be completed and tested before proceeding to the next
- All file paths use forward slashes for consistency
- JSON responses must be properly escaped
- Character restrictions (no "—ë", no long dashes) apply throughout
